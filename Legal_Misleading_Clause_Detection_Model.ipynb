{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "OicoJTeYtk-u"
   },
   "source": [
    "# **AI - POWERED LEGAL MISLEADING CLAUSE DETECTION MODEL IN TERMS & CONDITIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "sDrdFlv0v9tN"
   },
   "source": [
    "## **Problem Statement**\n",
    "\n",
    "\n",
    "- Terms and Conditions (T&C) agreements are notoriously long, complicated, and full of dense legal jargon—making them difficult for the average user to understand. Within this complexity, companies may insert biased, unfair, or misleading clauses that limit consumer rights, shift liability, or disproportionately favor the service provider.\n",
    "\n",
    "- Users frequently accept these agreements without reading or fully comprehending them, leading to unintended consequences. Detecting such problematic clauses currently requires manual legal expertise, which is time-consuming, costly, and inaccessible to most users.\n",
    "\n",
    "- While existing resources are limited, the Contract Understanding Atticus Dataset (CUAD) curated by The Atticus Project offers a promising solution. CUAD comprises over 13,000 expert annotations across 510 commercial legal contracts, covering 41 types of key clauses commonly identified in corporate legal reviews—ranging from governing law and expiration dates to exclusivity and most-favored-nation provisions.\n",
    "\n",
    "- This project aims to build an AI-powered Legal Assistant that leverages NLP and machine learning models trained on CUAD to:\n",
    "\n",
    "    - Detect potentially biased, unfair, or misleading clauses in T&C documents.\n",
    "\n",
    "    - Highlight these clauses for review.\n",
    "\n",
    "- By building upon the rigorously annotated CUAD dataset, we capitalize on a high-quality benchmark designed explicitly for legal contract review, enabling more accurate detection and interpretation of critical clauses. This approach can significantly reduce the time, cost, and expertise needed—empowering individuals and small organizations with improved access to legal insight and protection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "ZknHiTF5xCQu"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Zip File\n",
    "zip_file = \"CUAD_v1.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"CUAD_dataset\")  # folder to extract into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljWhbVYfxDh-",
    "outputId": "75ffd1da-a577-46c3-eaf2-f8ec7c5f669e"
   },
   "outputs": [],
   "source": [
    "# List all files and folders extracted\n",
    "import os\n",
    "os.listdir(\"CUAD_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PI_ti7MXw-1X",
    "outputId": "bd23cf3b-7f32-4d3e-e58f-16a21408eba3"
   },
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbhIychLxutO",
    "outputId": "cbeadd8a-94d4-4dc8-afb7-1f518868186b"
   },
   "outputs": [],
   "source": [
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "8WuHG-oh8HJT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "0S5lFH6Cqkoc"
   },
   "source": [
    "## **Load CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "mS62Le_88InK"
   },
   "outputs": [],
   "source": [
    "# ---------------- STEP 1: Paths ----------------\n",
    "CSV_PATH = \"/content/CUAD_dataset/CUAD_v1/master_clauses.csv\"\n",
    "EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fi0P6DKV8KJi",
    "outputId": "644b648c-657b-49c0-a979-4450c2fec9b9"
   },
   "outputs": [],
   "source": [
    "# ---------------- STEP 2: Load Dataset ----------------\n",
    "# Load master clauses from CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "# 4. Show first rows & column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "J3K-hT0Q9PWa",
    "outputId": "6aac8d88-007c-438e-f4e8-709045a7822f"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmKuVw9D9pMT",
    "outputId": "26f5caef-1936-4980-a47f-816275839262"
   },
   "outputs": [],
   "source": [
    "# Identify clause text columns (exclude ones ending in \"-Answer\")\n",
    "clause_columns = [col for col in df.columns if not col.endswith(\"-Answer\") and col not in [\"Filename\", \"Document Name\"]]\n",
    "\n",
    "# Melt into long format: one clause per row\n",
    "melted_df = df.melt(value_vars=clause_columns, var_name=\"label\", value_name=\"clause_text\")\n",
    "\n",
    "# Drop NaN or empty clauses\n",
    "melted_df = melted_df.dropna(subset=[\"clause_text\"])\n",
    "melted_df = melted_df[melted_df[\"clause_text\"].str.strip() != \"\"]\n",
    "\n",
    "print(melted_df.head())\n",
    "print(f\"Total clauses: {len(melted_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "VdzAIWdjrAKk"
   },
   "source": [
    "## **Text Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxNIZReo8Nrr",
    "outputId": "c0bf646f-97b9-417c-9fe5-b05147858e34"
   },
   "outputs": [],
   "source": [
    "pdf_folder = \"/content/CUAD_dataset/CUAD_v1/full_contract_pdf\"\n",
    "txt_folder = \"/content/CUAD_dataset/CUAD_v1/full_contract_txt\"\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Collect PDF texts\n",
    "pdf_data = []\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        full_path = os.path.join(pdf_folder, filename)\n",
    "        text = extract_text_from_pdf(full_path)\n",
    "        pdf_data.append({\"label\": \"Unknown\", \"clause_text\": text})\n",
    "\n",
    "# Collect TXT texts\n",
    "txt_data = []\n",
    "for filename in os.listdir(txt_folder):\n",
    "    if filename.lower().endswith(\".txt\"):\n",
    "        full_path = os.path.join(txt_folder, filename)\n",
    "        with open(full_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "        txt_data.append({\"label\": \"Unknown\", \"clause_text\": text})\n",
    "\n",
    "# Combine with CSV clauses\n",
    "pdf_df = pd.DataFrame(pdf_data)\n",
    "txt_df = pd.DataFrame(txt_data)\n",
    "full_df = pd.concat([melted_df, pdf_df, txt_df], ignore_index=True)\n",
    "\n",
    "print(full_df.head())\n",
    "print(f\"Total records: {len(full_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "RdFPuxiArLaM"
   },
   "source": [
    "## **Chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdrDLSjC_ws7",
    "outputId": "5a199685-046e-44f1-fe4f-ccceb740532b"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a text splitter (better for legal clauses)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # adjust based on legal clause length\n",
    "    chunk_overlap=100,  # keep context overlap\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for _, row in full_df.iterrows():\n",
    "    for chunk in text_splitter.split_text(row[\"clause_text\"]):\n",
    "        chunks.append({\"label\": row[\"label\"], \"text\": chunk})\n",
    "\n",
    "chunks_df = pd.DataFrame(chunks)\n",
    "print(f\"Total chunks created: {len(chunks_df)}\")\n",
    "print(chunks_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "pZjB4YZ-rQt0"
   },
   "source": [
    "## **Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13DbDrkw_1Cr",
    "outputId": "3a878f3d-3ae2-4ad8-acea-a21c5ce7ee07"
   },
   "outputs": [],
   "source": [
    "# ---------- Embedding ----------\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Load embedding model (no API key needed)\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode all chunks\n",
    "embeddings = embed_model.encode(chunks_df[\"text\"].tolist(), convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "zmjtXUuMrXU1"
   },
   "source": [
    "## **FAISS Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMEzPo2v_6_M",
    "outputId": "59f2440d-97ee-4101-82ac-c85a4979760f"
   },
   "outputs": [],
   "source": [
    "# ---------- FAISS Vector Store ----------\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"FAISS index size: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "sRok55rfrhMF"
   },
   "source": [
    "## **Defining Function For Retrieval Similar Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "gRuNII7TAAzS"
   },
   "outputs": [],
   "source": [
    "# ---------- Retrieval Function ----------\n",
    "def retrieve_similar_chunks(query, top_k=5):\n",
    "    query_emb = embed_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_emb, top_k)\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        results.append({\n",
    "            \"score\": float(distances[0][i]),\n",
    "            \"text\": chunks_df.iloc[idx][\"text\"],\n",
    "            \"label\": chunks_df.iloc[idx][\"label\"]\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "TTfMkp3lr8gF"
   },
   "source": [
    "### **Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9oYVCyHAHHb",
    "outputId": "59ae1fbe-e0e7-4211-acdc-9a2d35074171"
   },
   "outputs": [],
   "source": [
    "# ---------- Example Retrieval ----------\n",
    "query = \"termination clause without prior notice\"\n",
    "retrieved = retrieve_similar_chunks(query)\n",
    "\n",
    "print(\"\\nTop Matching Chunks:\")\n",
    "for r in retrieved:\n",
    "    print(f\"[{r['label']}] {r['text'][:200]}...\\nScore: {r['score']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "60XfVDYLsBZ0"
   },
   "source": [
    "## **Prepare Data For Generative Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_KBeg-GCYE7",
    "outputId": "3062e95d-afa8-4414-f014-997663171626"
   },
   "outputs": [],
   "source": [
    "# Prepare data for generative training\n",
    "train_data = []\n",
    "for _, row in chunks_df.iterrows():\n",
    "    if row[\"label\"] != \"Unknown\":  # only labeled data for supervised learning\n",
    "        prompt = f\"Explain why the following clause might be misleading:\\n\\n{row['text']}\"\n",
    "        response = f\"This clause is categorized as '{row['label']}' and may be misleading because ...\"\n",
    "        train_data.append({\"prompt\": prompt, \"response\": response})\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "eALi1ZzKsMt9"
   },
   "source": [
    "## **Training With a Generative AI Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evSrqMooDMmk",
    "outputId": "06cb9aa7-5081-496a-8e08-f5c47c89f4f3"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "h7qsurUoLxBm"
   },
   "outputs": [],
   "source": [
    "# Disable wandb\n",
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "DTUBiE-NL7W4"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "train_df = pd.DataFrame({\n",
    "    \"clause\": [\n",
    "        \"This agreement limits user rights.\",\n",
    "        \"The company may terminate without notice.\",\n",
    "        \"This clause ensures both parties are protected.\",\n",
    "        \"The user can cancel at any time.\"\n",
    "    ],\n",
    "    \"label\": [1, 1, 0, 0]   # 1 = misleading, 0 = not misleading\n",
    "})\n",
    "\n",
    "# HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# Load tokenizer & model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "C2k9tHSPsepl"
   },
   "source": [
    "### **Tokenize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "b471af98689d478ea9f1429b538aaca9",
      "b4ae3c57e46840399acdccb0ae6f174b",
      "508198506d0845ef922157aeb5e5f04b",
      "0222628641b84b4f87067752381a15be",
      "e5a6042620244bb9adfe7b56550b2e6a",
      "636e667ac57544be90ca195ff8076c1f",
      "0b89eacff3484a10a7f475ddf8d2ab40",
      "84305943104741e8a2612637d1315795",
      "f9dee92353524865bb65d6e9f011eaba",
      "f508574ce2a240cd986cfe9e81a9e5f6",
      "e72c0c62efa042f3890d2c9d88121b1c"
     ]
    },
    "id": "ka9S94RuL8Fl",
    "outputId": "cbb84036-f0ec-4d72-efee-08a438817d0e"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Tokenization\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"clause\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "tokenized_data = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Rename labels properly\n",
    "tokenized_data = tokenized_data.rename_column(\"label\", \"labels\")\n",
    "tokenized_data.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Train/Test split\n",
    "train_test = tokenized_data.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test[\"train\"]\n",
    "test_dataset = train_test[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "uW0hu2Sgsygs"
   },
   "source": [
    "### **Split dataset into train aand test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "AcGtFl8ltD0V"
   },
   "source": [
    "### **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "o4xCXPHvMG9G",
    "outputId": "ac8bf517-c609-440d-f1fe-f8455051db73"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "okkFGtaOtTx1"
   },
   "source": [
    "## **Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4YtfpyvQ-Je",
    "outputId": "2d1c3f04-57da-4615-d7c8-86e30e6400f5"
   },
   "outputs": [],
   "source": [
    "# Save model and tokenizer\n",
    "trainer.save_model()  # Saves to ./gen_ai_model\n",
    "tokenizer.save_pretrained(\"./gen_ai_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "id": "W88HVrevtaNV"
   },
   "source": [
    "## **Download into my local system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "cqbQ6yKBRAw-",
    "outputId": "0a1e9fe7-ff21-443f-e945-1c83cc8cd199"
   },
   "outputs": [],
   "source": [
    "# Option 1: Download to local machine\n",
    "!zip -r gen_ai_model.zip ./gen_ai_model\n",
    "from google.colab import files\n",
    "files.download(\"gen_ai_model.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
